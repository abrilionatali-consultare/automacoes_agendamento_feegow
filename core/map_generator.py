from pathlib import Path
from datetime import timedelta, datetime, date
from jinja2 import Environment, FileSystemLoader
from weasyprint import HTML
import pandas as pd
import re

from core.api_client import (
    fetch_agendamentos,
    list_profissionals,
    list_especialidades,
    list_salas,
    list_unidades,
    fetch_horarios_disponiveis,
    get_main_specialty_id,
    list_blocks
)

from core.utils import (
    build_matrices,
    render_pdf_from_template,
    to_time,
    periodo_from_time
)

from core.normalize_df import normalize_and_validate

# Carregamento de dados auxiliares
df_prof = list_profissionals()
df_esp = list_especialidades()
df_loc = list_salas()
df_unid = list_unidades()

# ==============================================================================
# FUN√á√ÉO AUXILIAR DE FILTRO DE BLOQUEIOS
# ==============================================================================
def _remove_blocked_slots(df_slots, start_date_str, end_date_str, unidade_id=None):
    """
    Remove linhas do DataFrame que coincidem com per√≠odos de bloqueio.
    Vers√£o Blindada: Corrige tipagem de unidades (str/int) e datas.
    """
    if df_slots.empty:
        return df_slots

    df_blocks = list_blocks(start_date=start_date_str, end_date=end_date_str)
    
    if df_blocks.empty:
        return df_slots

    print(f"DEBUG: Analisando bloqueios para {len(df_slots)} slots...")

    # 1. Prepara√ß√£o Robusta de Datas dos Slots
    # Tenta ler dayfirst=True (DD-MM-YYYY) padr√£o BR. Se falhar, tenta ISO.
    df_slots['_temp_date'] = pd.to_datetime(df_slots['data'], dayfirst=True, errors='coerce').dt.date
    # Fallback: Se gerou NaT (Not a Time), tenta for√ßar formato ISO
    mask_nat = df_slots['_temp_date'].isna()
    if mask_nat.any():
        df_slots.loc[mask_nat, '_temp_date'] = pd.to_datetime(df_slots.loc[mask_nat, 'data'], errors='coerce').dt.date
        
    df_slots['_temp_time'] = pd.to_datetime(df_slots['horario'], format="%H:%M:%S", errors='coerce').dt.time
    
    if 'profissional_id' in df_slots.columns:
        df_slots['profissional_id'] = pd.to_numeric(df_slots['profissional_id'], errors='coerce').fillna(0).astype(int)

    # 2. M√°scara de Exclus√£o
    mask_exclude = pd.Series([False] * len(df_slots), index=df_slots.index)

    # Garante que a unidade alvo seja Inteiro (se existir)
    target_unit = int(unidade_id) if unidade_id else None

    for _, block in df_blocks.iterrows():
        # --- A. VERIFICA√á√ÉO DE UNIDADE (CORRIGIDA) ---
        block_units = block.get('units')
        
        should_apply_block = False
        
        if target_unit is None:
            # Se n√£o estamos filtrando por unidade (Mapa Geral), aplica todos os bloqueios
            should_apply_block = True
        else:
            # Estamos gerando mapa para Unidade X. O bloqueio se aplica a X?
            
            # Cen√°rio 1: Lista de Unidades
            if isinstance(block_units, list) and len(block_units) > 0:
                # [CORRE√á√ÉO CR√çTICA]: Converte a lista do bloqueio para inteiros para garantir
                # Isso resolve o caso de ["12"] vs 12
                clean_units = []
                for u in block_units:
                    try: clean_units.append(int(u))
                    except: pass
                
                if target_unit in clean_units or 0 in clean_units:
                    should_apply_block = True
            
            # Cen√°rio 2: Fallback (Coluna antiga unidade_id)
            else:
                legacy_uid = block.get('unidade_id')
                try:
                    legacy_uid = int(legacy_uid) if legacy_uid is not None else 0
                except:
                    legacy_uid = 0
                
                if legacy_uid == 0 or legacy_uid == target_unit:
                    should_apply_block = True

        if not should_apply_block:
            continue

        # --- B. Verifica Data (Segura) ---
        # block['date_start'] j√° vem como date object do list_blocks
        m_date = (df_slots['_temp_date'] >= block['date_start']) & (df_slots['_temp_date'] <= block['date_end'])
        
        if not m_date.any(): continue

        # --- C. Verifica Hor√°rio ---
        blk_start = block['time_start'] if pd.notnull(block.get('time_start')) else time(0,0)
        blk_end = block['time_end'] if pd.notnull(block.get('time_end')) else time(23,59,59)
        
        m_time = (df_slots['_temp_time'] >= blk_start) & (df_slots['_temp_time'] <= blk_end)
        
        # --- D. Verifica Profissional ---
        blk_prof = int(block['professional_id']) if pd.notnull(block.get('professional_id')) else 0
        
        if blk_prof > 0:
            m_prof = (df_slots['profissional_id'] == blk_prof)
        else:
            m_prof = True # Afeta todos

        # Combina
        current_mask = m_date & m_time & m_prof
        mask_exclude = mask_exclude | current_mask

    # 3. Limpeza
    df_clean = df_slots[~mask_exclude].copy()
    df_clean.drop(columns=['_temp_date', '_temp_time'], inplace=True, errors='ignore')
    
    removidos = mask_exclude.sum()
    if removidos > 0:
        print(f"DEBUG: üõ°Ô∏è Bloqueio ativo! {removidos} slots da m√©dica/unidade foram removidos.")
        
    return df_clean

def generate_weekly_maps(start_date, unidade_id=None, output_dir="mapas_gerados"):
    """
    Fun√ß√£o de Mapa Semanal (Mantida a l√≥gica funcional e limpa).
    """
    start_date_str = start_date if isinstance(start_date, str) else start_date.strftime("%d-%m-%Y")
    df_unid_list = list_unidades()

    start_dt = datetime.strptime(start_date_str, "%d-%m-%Y")
    end_date_str = (start_dt + timedelta(days=6)).strftime("%d-%m-%Y")
    out_dir = Path(output_dir)
    out_dir.mkdir(parents=True, exist_ok=True)

    unidade_sel_id = None
    if unidade_id and unidade_id != 'Todas':
        filtro = df_unid_list[df_unid_list['nome_fantasia'] == unidade_id]
        if not filtro.empty:
            unidade_sel_id = int(filtro['unidade_id'].iloc[0])

    # Busca dados
    df_ag = fetch_agendamentos(start_date=start_date_str, end_date=end_date_str, unidade_id=unidade_sel_id)
    if df_ag.empty: return {"warning": "Vazio"}
    
    # Filtro de status v√°lidos para mapa
    required_status = [1, 7, 2, 3, 4]
    df_ag = df_ag[df_ag['status_id'].isin(required_status)]
    
    # Inje√ß√£o de Grade
    profs_ativos = df_ag["profissional_id"].unique()
    all_slots = []
    for p_id in profs_ativos:
        p_int = int(p_id)
        sid = get_main_specialty_id(p_int)
        if sid:
            vagas = fetch_horarios_disponiveis(unidade_sel_id, start_date_str, end_date_str, p_int, especialidade_id=int(sid))
            if not vagas.empty:
                vagas['agendamento_id'], vagas['status_id'] = 0, 0 
                all_slots.append(vagas)

    # Uni√£o
    if all_slots:
        df = pd.concat([df_ag, pd.concat(all_slots)], ignore_index=True)
        # Sincroniza√ß√£o simples para o semanal
        df['especialidade_id'] = df.groupby(['profissional_id', 'local_id'])['especialidade_id'].transform(lambda x: x.ffill().bfill())
    else:
        df = df_ag.copy()

    # Aplica filtro de bloqueios
    df = _remove_blocked_slots(df, start_date_str, end_date_str, unidade_id=unidade_sel_id)
    if df.empty: return {"warning": "Todos os hor√°rios est√£o bloqueados."}

    # Merges
    df = df.merge(df_esp[['especialidade_id', 'nome']], on="especialidade_id", how="left").rename(columns={'nome': 'especialidade'})
    df = df.merge(df_prof[['profissional_id', 'nome']], on="profissional_id", how="left").rename(columns={'nome': 'nome_profissional'})
    df = df.merge(df_loc[['id', 'local']], left_on="local_id", right_on="id", how="left").rename(columns={'local': 'sala'})
    
    # Normaliza√ß√£o
    df_final, _ = normalize_and_validate(df)

    # Remove salas inv√°lidas para o mapa
    remover = ['LABORAT√ìRIO', 'RAIO X', 'SALA DE VACINA', 'COLETA DOMICILIAR', 'VACINA', 'LABORATORIO']
    df_final = df_final[~df_final['sala'].isin(remover)]
    
    # Fix Unidade
    if unidade_id and unidade_id != 'Todas':
        df_final['unidade'] = unidade_id
    else:
        if 'unidade_id' in df_final.columns:
            df_final = df_final.merge(df_unid_list[['unidade_id', 'nome_fantasia']], on="unidade_id", how="left")
            df_final.rename(columns={'nome_fantasia': 'unidade'}, inplace=True)
            
    df_final['unidade'] = df_final['unidade'].fillna("Geral")
    df_final = df_final[~df_final['sala'].str.upper().isin(['SALA DE VACINA', 'LABORAT√ìRIO', 'RAIO X'])]

    # Gera√ß√£o
    out_bytes = {}
    for unidade in df_final["unidade"].unique():
        if not unidade: continue
        matrices, occ, days = build_matrices(df_final[df_final["unidade"] == unidade], include_taxa=False)
        pdf_bytes = render_pdf_from_template(unidade, matrices, occ, days, start_date_str, end_date_str, "templates/semanal2.html", cell_font_size_px=9, return_bytes=True)
        out_bytes[unidade] = pdf_bytes
    return out_bytes

def generate_daily_maps(start_date, unidade_id=None, output_dir="mapas_gerados"):
    start_date_str = start_date if isinstance(start_date, str) else start_date.strftime("%d-%m-%Y")
    
    DE_PARA_UNIDADES_VAGAS = { 39867: 12, 12: 12 }
    df_unid_list = list_unidades()

    # 1. Identifica√ß√£o da Unidade
    unidade_sel_id = None
    if unidade_id and unidade_id != 'Todas':
        filtro = df_unid_list[df_unid_list['nome_fantasia'] == unidade_id]
        if not filtro.empty:
            raw_id = int(filtro['unidade_id'].iloc[0])
            unidade_sel_id = DE_PARA_UNIDADES_VAGAS.get(raw_id, raw_id)

    # 2. Busca Agendamentos
    df_ag = fetch_agendamentos(start_date=start_date_str, end_date=start_date_str, unidade_id=unidade_sel_id)
    if df_ag.empty: return {"warning": "Sem agendamentos para esta data."}

    # Garante tipagem inicial
    for col in ['profissional_id', 'local_id', 'especialidade_id', 'agendamento_id', 'status_id']:
        if col in df_ag.columns:
            df_ag[col] = pd.to_numeric(df_ag[col], errors='coerce').fillna(0).astype(int)

    # Remo√ß√£o de status inv√°lidos
    required_status = [1, 7, 2, 3, 4]
    df_ag = df_ag[df_ag['status_id'].isin(required_status)]

    # 3. Inje√ß√£o de Grade
    profs = df_ag["profissional_id"].unique()
    all_slots = []
    
    for p_id in profs:
        p_int = int(p_id)
        if p_int == 0: continue

        specs_do_dia = df_ag[df_ag['profissional_id'] == p_int]['especialidade_id'].unique()
        specs_do_dia = [int(s) for s in specs_do_dia if s > 0]
        
        # Se n√£o achou especialidade no agendamento, busca a principal para poder consultar a grade
        if not specs_do_dia:
            sid_main = get_main_specialty_id(p_int)
            if sid_main: specs_do_dia = [sid_main]
            
        for sid in specs_do_dia:
            v_df = fetch_horarios_disponiveis(
                unidade_id=unidade_sel_id,
                data_start=start_date_str, 
                data_end=start_date_str, 
                profissional_id=p_int, 
                especialidade_id=int(sid)
            )
            
            if not v_df.empty:
                v_df['agendamento_id'] = 0
                v_df['status_id'] = 0
                v_df['profissional_id'] = p_int
                v_df['especialidade_id'] = int(sid)
                
                if 'local_id' not in v_df.columns or v_df['local_id'].sum() == 0:
                     locais = df_ag[df_ag['profissional_id'] == p_int]['local_id'].unique()
                     local_fallback = locais[0] if len(locais) > 0 else 0
                     v_df['local_id'] = int(local_fallback)
                
                all_slots.append(v_df)

    if all_slots:
        df_grade = pd.concat(all_slots, ignore_index=True)
        df_grade = df_grade.drop_duplicates(subset=['profissional_id', 'horario', 'local_id'])
        df = pd.concat([df_ag, df_grade], ignore_index=True)
    else:
        df = df_ag.copy()

    # Aplica filtro de bloqueios
    df = _remove_blocked_slots(df, start_date_str, start_date_str, unidade_id=unidade_sel_id)
    if df.empty: return {"warning": "Todos os agendamentos/vagas coincidem com bloqueios de agenda."}

    # ==============================================================================
    # [PASSO 1] RECUPERA√á√ÉO E SANEAMENTO DE DADOS (Antes do Merge)
    # ==============================================================================
    
    # 1. Garante que IDs sejam num√©ricos
    df['profissional_id'] = pd.to_numeric(df['profissional_id'], errors='coerce').fillna(0).astype(int)
    if 'especialidade_id' not in df.columns: df['especialidade_id'] = 0
    df['especialidade_id'] = pd.to_numeric(df['especialidade_id'], errors='coerce').fillna(0).astype(int)

    # 2. Remove imediatamente linhas sem m√©dico (profissional_id == 0)
    # Se n√£o tem ID de m√©dico, √© lixo de base e n√£o serve para o mapa.
    df = df[df['profissional_id'] > 0]

    # 3. Tenta salvar especialidade zerada buscando a principal do m√©dico
    mask_sem_spec = df['especialidade_id'] == 0
    
    if mask_sem_spec.any():
        print(f"DEBUG: Tentando recuperar especialidade para {mask_sem_spec.sum()} registros...")
        
        def recuperar_spec(row):
            # Se j√° tem, mant√©m
            if row['especialidade_id'] > 0: return row['especialidade_id']
            # Se n√£o tem, busca na API/Cache
            pid = row['profissional_id']
            spec_recuperada = get_main_specialty_id(pid)
            return spec_recuperada if spec_recuperada else 0
            
        # Aplica a recupera√ß√£o linha a linha onde necess√°rio
        df.loc[mask_sem_spec, 'especialidade_id'] = df.loc[mask_sem_spec].apply(recuperar_spec, axis=1)

    # ==============================================================================

    # 5. Merges (Agora com IDs mais limpos)
    df = df.merge(df_esp[['especialidade_id', 'nome']], on="especialidade_id", how="left").rename(columns={'nome': 'especialidade'})
    df = df.merge(df_prof[['profissional_id', 'nome']], on="profissional_id", how="left").rename(columns={'nome': 'nome_profissional'})
    df = df.merge(df_loc[['id', 'local']], left_on="local_id", right_on="id", how="left").rename(columns={'local': 'sala'})

    # ==============================================================================
    # [PASSO 2] LIMPEZA FINAL (P√≥s-Merge)
    # ==============================================================================
    
    # Converte para string para analisar o conte√∫do textual
    df['nome_profissional'] = df['nome_profissional'].astype(str).str.strip()
    df['especialidade'] = df['especialidade'].astype(str).str.strip()
    df['sala'] = df['sala'].astype(str).str.strip()
    
    # Termos proibidos (indica falha no merge ou dado nulo original)
    termos_invalidos = ['nan', 'none', '', 'null', 'nat']
    
    # Filtros: Mant√©m apenas se O NOME E A ESPECIALIDADE forem v√°lidos
    keep_prof = ~df['nome_profissional'].str.lower().isin(termos_invalidos)
    keep_spec = ~df['especialidade'].str.lower().isin(termos_invalidos)
    keep_sala = ~df['sala'].str.lower().isin(termos_invalidos)
    
    # Aplica o corte
    df = df[keep_prof & keep_spec & keep_sala]
    
    # ==============================================================================

    # Normaliza√ß√£o
    df_final, _ = normalize_and_validate(df)
    
    remover_visual = ['PR√â ATENDIMENTO', 'COLETA DOMICILIAR', 'TELEMEDICINA']
    df_final = df_final[~df_final['sala'].str.upper().str.contains('|'.join(remover_visual), na=False)]
    
    df_final['time'] = df_final['horario'].apply(to_time)
    df_final['periodo'] = df_final['time'].apply(periodo_from_time)
    
    # 6. Agrupamento
    master_data = {}
    dados_uni = {
        "Manh√£": [], "Tarde": [], 
        "totais": {'Manh√£': {'grade': 0, 'pacientes': 0, 'taxa': 0}, 'Tarde': {'grade': 0, 'pacientes': 0, 'taxa': 0}, 'dia': {'grade': 0, 'pacientes': 0, 'taxa': 0}}
    }
    
    grouped = df_final.groupby(['sala', 'nome_profissional', 'especialidade', 'periodo']).agg(
        pacientes_reais=('agendamento_id', lambda x: (pd.to_numeric(x, errors='coerce').fillna(0) > 0).sum()),
        grade_total=('horario', 'count')
    ).reset_index()

    # Ordena√ß√£o Natural
    def natural_key(text):
        return [int(c) if c.isdigit() else c.lower() for c in re.split(r'(\d+)', str(text))]
    grouped['sort_key'] = grouped['sala'].apply(natural_key)
    grouped = grouped.sort_values(by='sort_key')

    for _, row in grouped.iterrows():
        g = int(row['grade_total'])
        p = int(row['pacientes_reais'])
        if g < p: g = p 
        
        taxa = (p / g * 100) if g > 0 else 0
        
        item = {
            'sala': row['sala'], 'periodo_detalhe': row['periodo'], 'especialidade': row['especialidade'],
            'medico': row['nome_profissional'], 'ocupacao': p, 'vagas_grade': g, 'taxa_ocupacao': f"{taxa:.1f}%", 'taxa_num': taxa
        }
        
        if row['periodo'] in ["Manh√£", "Tarde"]:
            dados_uni[row['periodo']].append(item)
            dados_uni['totais'][row['periodo']]['grade'] += g
            dados_uni['totais'][row['periodo']]['pacientes'] += p

    for per in ['Manh√£', 'Tarde']:
        g_t = dados_uni['totais'][per]['grade']
        p_t = dados_uni['totais'][per]['pacientes']
        dados_uni['totais'][per]['taxa'] = (p_t / g_t * 100) if g_t > 0 else 0
        dados_uni['totais']['dia']['grade'] += g_t
        dados_uni['totais']['dia']['pacientes'] += p_t

    g_d = dados_uni['totais']['dia']['grade']
    p_d = dados_uni['totais']['dia']['pacientes']
    dados_uni['totais']['dia']['taxa'] = (p_d / g_d * 100) if g_d > 0 else 0

    # 7. C√°lculo de Salas F√≠sicas (Mantido e ajustado)
    salas_ignorar_contagem = ['PR√â ATENDIMENTO', 'COLETA DOMICILIAR', "TELEMEDICINA", "TESTE"]
    
    if 'unidade_id' in df_loc.columns and unidade_sel_id:
        df_salas_unid = df_loc[df_loc['unidade_id'] == int(unidade_sel_id)]
        if df_salas_unid.empty: df_salas_unid = df_loc 
    else:
        df_salas_unid = df_loc.copy()
    
    mask_ignorar = df_salas_unid['local'].astype(str).str.upper().apply(lambda x: any(ign in x for ign in salas_ignorar_contagem))
    total_salas_fisicas = df_salas_unid[~mask_ignorar]['local'].nunique()
    
    salas_ativas_manha = df_final[df_final['periodo'] == 'Manh√£']['sala'].nunique()
    salas_ativas_tarde = df_final[df_final['periodo'] == 'Tarde']['sala'].nunique()
    salas_ativas_dia = df_final['sala'].nunique()

    def calc_taxa(usadas, total):
        return (usadas / total * 100) if total > 0 else 0

    dados_uni['metricas_salas'] = {
        'total_salas': total_salas_fisicas,
        'ativas_manha': salas_ativas_manha,
        'taxa_manha': calc_taxa(salas_ativas_manha, total_salas_fisicas),
        'ativas_tarde': salas_ativas_tarde,
        'taxa_tarde': calc_taxa(salas_ativas_tarde, total_salas_fisicas),
        'ativas_dia': salas_ativas_dia,
        'taxa_dia': calc_taxa(salas_ativas_dia, total_salas_fisicas)
    }

    unidade_chave = unidade_id if unidade_id else "Geral"
    master_data[unidade_chave] = dados_uni

    tpl = Environment(loader=FileSystemLoader('.')).get_template("templates/diario.html")
    html = tpl.render(unidade=unidade_chave, all_data=master_data, date_str=start_date_str, 
                      grand_total=dados_uni['totais']['dia']['pacientes'], 
                      generated=datetime.now().strftime("%d/%m/%Y %H:%M"))
    
    return {unidade_chave: HTML(string=html).write_pdf()}